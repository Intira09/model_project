# -*- coding: utf-8 -*-
"""S10 (ใหม่).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vcRAn2bbmf0WHi4KwxcD3C6flDiT1rcY

# โค้ดเดิม
"""

!pip install pythainlp

import requests
import json
from pythainlp.tokenize import word_tokenize

# ---------- ตั้งค่า ----------
TNER_API_KEY = '' # add Apikey
CYBERBULLY_API_KEY = '' # add Apikey

personal_pronoun_1 = {"หนู", "ข้า", "กู"}
personal_pronoun_2 = {"คุณ", "แก", "เธอ", "ตัวเอง", "เอ็ง", "มึง"}
all_personal_pronouns = personal_pronoun_1.union(personal_pronoun_2)

# ---------- ฟังก์ชันตรวจ ----------
def check_named_entities(text):
    url = "https://api.aiforthai.in.th/tner"
    headers = {"Apikey": TNER_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            ner_result = response.json()
            bad_tags = {'ABB_DES', 'ABB_TTL', 'ABB_ORG', 'ABB_LOC', 'ABB'}
            bad_entities = [ent['word'] for ent in ner_result.get("entities", []) if ent['tag'] in bad_tags]
            if bad_entities:
                return True, bad_entities
    except:
        pass
    return False, []

def check_cyberbully(text):
    url = "https://api.aiforthai.in.th/cyberbully"
    headers = {"Apikey": CYBERBULLY_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            result = response.json()
            if result.get("bully", "no") == "yes":
                bully_words = result.get("bully_words") or result.get("bully_phrases") or [text]
                return True, bully_words
    except:
        pass
    return False, []

def check_personal_pronouns(text):
    tokens = word_tokenize(text, engine="newmm")
    found_pronouns = [token for token in tokens if token in all_personal_pronouns]
    if found_pronouns:
        return True, found_pronouns
    return False, []

# ---------- ตรวจคำตอบนักเรียน 1 คน ----------
def score_single_student_answer(answer_text):
    mistakes = []

    ne_flag, ne_words = check_named_entities(answer_text)
    if ne_flag:
        mistakes.append({"type": "Named Entity", "words": ne_words})

    bully_flag, bully_words = check_cyberbully(answer_text)
    if bully_flag:
        mistakes.append({"type": "Cyberbully", "words": bully_words})

    pronoun_flag, pronouns = check_personal_pronouns(answer_text)
    if pronoun_flag:
        mistakes.append({"type": "Personal Pronoun", "words": pronouns})

    # กำหนดคะแนน
    mistake_count = len(mistakes)
    if mistake_count == 0:
        score = 2
    elif mistake_count == 1:
        score = 1
    else:
        score = 0

    output = {
        "student_answer": answer_text,
        "score": score,
        "mistakes": mistakes if mistakes else "ไม่มีข้อผิดพลาด"
    }

    # แสดงผล JSON
    print(json.dumps(output, ensure_ascii=False, indent=2))

# ---------- ตัวอย่างการเรียกใช้งาน ----------
student_answer = """เห็นด้วย เพราะ ถ้าเราใช้สื่อ ออนไลน์ไม่ถูกต้องหรือแสดงความคิดเห็นในทางที่ไม่ถูกต้อง
อาจทำให้ฝ่ายที่ได้รับความคิดเห็นนั้นไม่สบายใจหรือกังวลในปัญหาของตนเอง
ทำให้เกิดความไม่มั่นใจในตัวเองจนทำให้เกิดความเข้าใจผิดและสร้างความเสื่อมเสีย
ให้แก่ผู้อื่น ดังนั้นการใช้สื่อสารออนไลน์ด้วยเจตนาแอบแฝงจึงมีผลกระทบทางด้านอื่นๆ"""

score_single_student_answer(student_answer)

"""# รวม"""

import requests
import json
from pythainlp.tokenize import word_tokenize

# ---------- ตั้งค่า API KEY ----------
TNER_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจ Named Entity
CYBERBULLY_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจคำรุนแรง/บูลลี่

# ---------- เกณฑ์ที่ใช้ตรวจ ----------
# เกณฑ์ 3: ไม่ใช้คำสรรพนามที่ไม่ถูกต้องตามหลักการแสดงความคิดเห็น
personal_pronoun_1 = {"หนู", "เรา", "ข้า", "กู"}  # บุรุษที่ 1 (รวม "เรา" เอกพจน์)
personal_pronoun_2 = {"คุณ", "เธอ", "แก", "ตัวเอง", "เอ็ง", "มึง"}  # บุรุษที่ 2
all_personal_pronouns = personal_pronoun_1.union(personal_pronoun_2)

# ---------- ฟังก์ชันตรวจ ----------

# เกณฑ์ 1: ไม่กล่าวพาดพิงบุคคลหรือองค์กรให้เกิดความเสียหาย
def check_named_entities(text):
    url = "https://api.aiforthai.in.th/tner"
    headers = {"Apikey": TNER_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            ner_result = response.json()
            # tag ที่ถือว่าไม่เหมาะสม เช่น ชื่อย่อของบุคคล/องค์กร
            bad_tags = {'ABB_DES', 'ABB_TTL', 'ABB_ORG', 'ABB_LOC', 'ABB'}
            bad_entities = [ent['word'] for ent in ner_result.get("entities", []) if ent['tag'] in bad_tags]
            if bad_entities:
                return True, bad_entities
    except:
        pass
    return False, []

# เกณฑ์ 2: ไม่ใช้คำรุนแรง ไม่ใช้คำสบถ ไม่ใช้คำหยาบ
def check_cyberbully(text):
    url = "https://api.aiforthai.in.th/cyberbully"
    headers = {"Apikey": CYBERBULLY_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            result = response.json()
            if result.get("bully", "no") == "yes":
                bully_words = result.get("bully_words") or result.get("bully_phrases") or [text]
                return True, bully_words
    except:
        pass
    return False, []

# เกณฑ์ 3: ตรวจคำสรรพนามที่ไม่ถูกต้องตามหลักการ
def check_personal_pronouns(text):
    tokens = word_tokenize(text, engine="newmm")
    found_pronouns = [token for token in tokens if token in all_personal_pronouns]
    if found_pronouns:
        return True, found_pronouns
    return False, []

# ---------- ตรวจคำตอบนักเรียน 1 คน ----------
def score_single_student_answer(answer_text):
    mistakes = []

    # ตรวจพาดพิงบุคคล/องค์กร
    ne_flag, ne_words = check_named_entities(answer_text)
    if ne_flag:
        mistakes.append({"type": "Named Entity", "words": ne_words})

    # ตรวจคำรุนแรง/บูลลี่
    bully_flag, bully_words = check_cyberbully(answer_text)
    if bully_flag:
        mistakes.append({"type": "Cyberbully", "words": bully_words})

    # ตรวจสรรพนามไม่ถูกต้อง
    pronoun_flag, pronouns = check_personal_pronouns(answer_text)
    if pronoun_flag:
        mistakes.append({"type": "Personal Pronoun", "words": pronouns})

    # เกณฑ์การให้คะแนน (2 = ดี, 1 = พอใช้, 0 = ต้องปรับปรุง)
    mistake_count = len(mistakes)
    if mistake_count == 0:
        score = 2
    elif mistake_count == 1:
        score = 1
    else:
        score = 0

    output = {
        "student_answer": answer_text,
        "score": score,
        "mistakes": mistakes if mistakes else "ไม่มีข้อผิดพลาด"
    }

    # แสดงผล JSON
    print(json.dumps(output, ensure_ascii=False, indent=2))

# ---------- ตัวอย่างการเรียกใช้งาน ----------
student_answer = """เห็นด้วย เพราะเป็นการกล่าวถึงประโยชน์และโทษของการใช้สื่อสังคม(Social Media)
หรือที่คนทั้วๆไปนั้นเรียกว่า สื่อออนไลน์ ซึ่งทำให้ผู้อ่านนั้นเข้าใจและรู้วิธีการ-
ใช้งานสื่อสังคม(Social Media)ได้ถูกวิธีและไม่ให้เป็นโทษแก่สังคม ทั้งทำให้
ผู้อ่านใช้ข้อมูลที่ได้ในการนำไปต่อยอดเพื่อเป็นประโยชน์ต่อตนเองในอนาคต และ
เป็นการสร้างภูมิคุ้มกันรู้ทั้นสื่อ เพื่อให้ไม่ตกเป็นเหยื่อทางการตลาดได้อีกด้วย"""

score_single_student_answer(student_answer)

import requests
import json
import pandas as pd
from pythainlp.tokenize import word_tokenize

# ---------- ตั้งค่า API KEY ----------
TNER_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจ Named Entity
CYBERBULLY_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจคำรุนแรง/บูลลี่

# ---------- เกณฑ์ที่ใช้ตรวจ ----------
personal_pronoun_1 = {"หนู", "ข้า", "กู"}
personal_pronoun_2 = {"คุณ", "เธอ", "แก", "ตัวเอง", "เอ็ง", "มึง","เขา"}
all_personal_pronouns = personal_pronoun_1.union(personal_pronoun_2)


# ---------- ฟังก์ชันตรวจ ----------
def check_named_entities(text):
    url = "https://api.aiforthai.in.th/tner"
    headers = {"Apikey": TNER_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            ner_result = response.json()
            bad_tags = {'ABB_DES', 'ABB_TTL', 'ABB_ORG', 'ABB_LOC', 'ABB'}
            bad_entities = [ent['word'] for ent in ner_result.get("entities", []) if ent['tag'] in bad_tags]
            if bad_entities:
                return True, bad_entities
    except:
        pass
    return False, []


def check_cyberbully(text):
    url = "https://api.aiforthai.in.th/cyberbully"
    headers = {"Apikey": CYBERBULLY_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            result = response.json()
            if result.get("bully", "no") == "yes":
                bully_words = result.get("bully_words") or result.get("bully_phrases") or [text]
                return True, bully_words
    except:
        pass
    return False, []


def check_personal_pronouns(text):
    tokens = word_tokenize(text, engine="newmm")
    found_pronouns = [token for token in tokens if token in all_personal_pronouns]
    if found_pronouns:
        return True, found_pronouns
    return False, []


# ---------- ประเมินคำตอบนักเรียน ----------
def evaluate_student_answer(answer_text):
    mistakes = []

    ne_flag, ne_words = check_named_entities(answer_text)
    if ne_flag:
        mistakes.append({"type": "Named Entity", "words": ne_words})

    bully_flag, bully_words = check_cyberbully(answer_text)
    if bully_flag:
        mistakes.append({"type": "Cyberbully", "words": bully_words})

    pronoun_flag, pronouns = check_personal_pronouns(answer_text)
    if pronoun_flag:
        mistakes.append({"type": "Personal Pronoun", "words": pronouns})

    mistake_count = len(mistakes)
    if mistake_count == 0:
        score = 2
    elif mistake_count == 1:
        score = 1
    else:
        score = 0

    return {
        "score": score,
        "mistakes": mistakes if mistakes else "ไม่มีข้อผิดพลาด"
    }


# ---------- ประเมินทั้ง DataFrame ----------
def evaluate_students(df, answer_column="answer"):
    all_results = []
    for idx, row in df.iterrows():
        ans = str(row.get(answer_column, ""))

        result = evaluate_student_answer(ans)

        row_result = row.to_dict()
        row_result.update({
            #"student_answer": ans,
            "score": result["score"],
            "mistakes": json.dumps(result["mistakes"], ensure_ascii=False)
        })
        all_results.append(row_result)

    return pd.DataFrame(all_results)


# ---------- ตัวอย่างเรียกใช้ ----------
if __name__ == "__main__":
    input_csv = "/content/drive/MyDrive/S10(Sheet1).csv"      # ไฟล์ที่คุณอัปโหลด
    output_csv = "/content/sample_data/score1_S10.csv"     # ไฟล์ผลลัพธ์ที่ต้องการบันทึก

    df = pd.read_csv(input_csv)
    results_df = evaluate_students(df, answer_column="student_answer_2")  # ถ้าคอลัมน์ชื่อไม่ใช่ answer ให้แก้ตรงนี้

    results_df.to_csv(output_csv, index=False, encoding="utf-8-sig")

    print("✅ ประเมินเสร็จสิ้น บันทึกไฟล์แล้วที่:", output_csv)

"""# ปรับสรรพนามบุรุษที่ 2 ได้ 86

https://silpakorn-my.sharepoint.com/:x:/g/personal/singtong_c2_su_ac_th/EaAfOngkz8ZJsrl7Lkjk9RoBwPb3_qLDnrhx8wuNG308JA?e=WDXSpc
"""

import requests
import json
import pandas as pd
from pythainlp.tokenize import word_tokenize

# ---------- ตั้งค่า API KEY ----------
TNER_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจ Named Entity
CYBERBULLY_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจคำรุนแรง/บูลลี่

# ---------- เกณฑ์ที่ใช้ตรวจ ----------
personal_pronoun_1 = {"หนู", "ข้า", "กู","ดิฉัน"}
personal_pronoun_2 = {"คุณ", "เธอ", "แก", "ตัวเอง", "เอ็ง", "มึง"}
all_personal_pronouns = personal_pronoun_1.union(personal_pronoun_2)


# ---------- ฟังก์ชันตรวจ ----------
def check_named_entities(text):
    url = "https://api.aiforthai.in.th/tner"
    headers = {"Apikey": TNER_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            ner_result = response.json()
            bad_tags = {'ABB_DES', 'ABB_TTL', 'ABB_ORG', 'ABB_LOC', 'ABB'}
            bad_entities = [ent['word'] for ent in ner_result.get("entities", []) if ent['tag'] in bad_tags]
            if bad_entities:
                return True, bad_entities
    except:
        pass
    return False, []

def check_cyberbully(text):
    url = "https://api.aiforthai.in.th/cyberbully"
    headers = {"Apikey": CYBERBULLY_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            result = response.json()
            if result.get("bully", "no") == "yes":
                bully_words = result.get("bully_words") or result.get("bully_phrases") or [text]
                return True, bully_words
    except:
        pass
    return False, []

def check_personal_pronouns(text):
    tokens = word_tokenize(text, engine="newmm")
    found_pronouns = []

    for i, tok in enumerate(tokens):
        if tok in all_personal_pronouns:
            if tok == "ตัวเอง":
                # 1) ถ้าอยู่ต้นประโยค -> บุรุษที่ 2 (ผิด)
                if i == 0:
                    found_pronouns.append(tok + "(บุรุษที่ 2)")
                # 2) ถ้าอยู่หลัง "ด้วย", "ของ" -> reflexive (ไม่ผิด)
                elif i > 0 and tokens[i-1] in {"ด้วย", "ของ"}:
                    continue
                # 3) กรณีอื่น -> ไม่ถือว่าผิด
                else:
                    continue
            else:
                # กรณีคำอื่น เช่น กู, มึง, คุณ ฯลฯ → ผิด
                found_pronouns.append(tok)

    if found_pronouns:
        return True, found_pronouns
    return False, []

# ---------- ประเมินคำตอบนักเรียน ----------
def evaluate_student_answer(answer_text):
    mistakes = []

    ne_flag, ne_words = check_named_entities(answer_text)
    if ne_flag:
        mistakes.append({"type": "Named Entity", "words": ne_words})

    bully_flag, bully_words = check_cyberbully(answer_text)
    if bully_flag:
        mistakes.append({"type": "Cyberbully", "words": bully_words})

    pronoun_flag, pronouns = check_personal_pronouns(answer_text)
    if pronoun_flag:
        mistakes.append({"type": "Personal Pronoun", "words": pronouns})

    mistake_count = len(mistakes)
    if mistake_count == 0:
        score = 2
    elif mistake_count == 1:
        score = 1
    else:
        score = 0

    return {
        "score": score,
        "mistakes": mistakes if mistakes else "ไม่มีข้อผิดพลาด"
    }


# ---------- ประเมินทั้ง DataFrame ----------
def evaluate_students(df, answer_column="answer"):
    all_results = []
    for idx, row in df.iterrows():
        ans = str(row.get(answer_column, ""))

        result = evaluate_student_answer(ans)

        row_result = row.to_dict()
        row_result.update({
            #"student_answer": ans,
            "score": result["score"],
            "mistakes": json.dumps(result["mistakes"], ensure_ascii=False)
        })
        all_results.append(row_result)

    return pd.DataFrame(all_results)


# ---------- ตัวอย่างเรียกใช้ ----------
if __name__ == "__main__":
    input_csv = "/content/drive/MyDrive/S10(Sheet1).csv"      # ไฟล์ที่คุณอัปโหลด
    output_csv = "/content/sample_data/score2_S10.csv"     # ไฟล์ผลลัพธ์ที่ต้องการบันทึก

    df = pd.read_csv(input_csv)
    results_df = evaluate_students(df, answer_column="student_answer_2")  # ถ้าคอลัมน์ชื่อไม่ใช่ answer ให้แก้ตรงนี้

    results_df.to_csv(output_csv, index=False, encoding="utf-8-sig")

    print("✅ ประเมินเสร็จสิ้น บันทึกไฟล์แล้วที่:", output_csv)

"""# ปรับคำว่า "แก" เพิ่มคำว่า "ดิฉัน" ได้ 87/100

https://silpakorn-my.sharepoint.com/:x:/g/personal/singtong_c2_su_ac_th/EctyEbYwzBFPi5pXRwR5SH4BW2DMu5k6CFn8_Q5sEammFA?e=TYhlqc
"""

import requests
import json
import re
import pandas as pd
from pythainlp.tokenize import word_tokenize

# ---------- ตั้งค่า API KEY ----------
TNER_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจ Named Entity
CYBERBULLY_API_KEY = 'PYJ6lQwGuvr8w7OJVThpu3T0yUlrC3af'  # ใส่ API Key สำหรับตรวจคำรุนแรง/บูลลี่

# ---------- เกณฑ์ที่ใช้ตรวจ ----------
personal_pronoun_1 = {"หนู", "ข้า", "กู","ดิฉัน"}
personal_pronoun_2 = {"คุณ", "เธอ", "แก", "ตัวเอง", "เอ็ง", "มึง"}
all_personal_pronouns = personal_pronoun_1.union(personal_pronoun_2)


# ---------- ฟังก์ชันตรวจ ----------
def check_named_entities(text):
    url = "https://api.aiforthai.in.th/tner"
    headers = {"Apikey": TNER_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            ner_result = response.json()
            bad_tags = {'ABB_DES', 'ABB_TTL', 'ABB_ORG', 'ABB_LOC', 'ABB'}
            bad_entities = [ent['word'] for ent in ner_result.get("entities", []) if ent['tag'] in bad_tags]
            if bad_entities:
                return True, bad_entities
    except:
        pass
    return False, []

def check_cyberbully(text):
    url = "https://api.aiforthai.in.th/cyberbully"
    headers = {"Apikey": CYBERBULLY_API_KEY}
    data = {"text": text}
    try:
        response = requests.post(url, headers=headers, data=data)
        if response.status_code == 200:
            result = response.json()
            if result.get("bully", "no") == "yes":
                bully_words = result.get("bully_words") or result.get("bully_phrases") or [text]
                return True, bully_words
    except:
        pass
    return False, []

def is_pronoun_gae(text):
    """
    คืนค่า True ถ้า "แก" เป็นคำโดดๆ
    คืนค่า False ถ้า "แก" เป็นส่วนหนึ่งของคำอื่น
    """
    # \b ใช้แทนขอบเขตคำ แต่ภาษาไทยไม่มีช่องว่างชัดเจน
    # เราเลยใช้ lookaround แทน
    pattern = r'(?<![ก-๙A-Za-z])แก(?![ก-๙A-Za-z])'
    return bool(re.search(pattern, text))

def check_personal_pronouns(text):
    tokens = word_tokenize(text, engine="newmm")
    found_pronouns = []

    for i, tok in enumerate(tokens):
        if tok in all_personal_pronouns:
            if tok == "ตัวเอง":
                if i == 0:
                    found_pronouns.append(tok + "(บุรุษที่ 2)")
                elif i > 0 and tokens[i-1] in {"ด้วย", "ของ"}:
                    continue
                else:
                    continue

            if tok == "แก":
                # ใช้ regex ตรวจว่า "แก" เป็นคำโดดๆ จริง
                if not is_pronoun_gae(text):
                    continue

            found_pronouns.append(tok)

    if found_pronouns:
        return True, found_pronouns
    return False, []

# ---------- ประเมินคำตอบนักเรียน ----------
def evaluate_student_answer(answer_text):
    mistakes = []

    ne_flag, ne_words = check_named_entities(answer_text)
    if ne_flag:
        mistakes.append({"type": "Named Entity", "words": ne_words})

    bully_flag, bully_words = check_cyberbully(answer_text)
    if bully_flag:
        mistakes.append({"type": "Cyberbully", "words": bully_words})

    pronoun_flag, pronouns = check_personal_pronouns(answer_text)
    if pronoun_flag:
        mistakes.append({"type": "Personal Pronoun", "words": pronouns})

    mistake_count = len(mistakes)
    if mistake_count == 0:
        score = 2
    elif mistake_count == 1:
        score = 1
    else:
        score = 0

    return {
        "score": score,
        "mistakes": mistakes if mistakes else "ไม่มีข้อผิดพลาด"
    }


# ---------- ประเมินทั้ง DataFrame ----------
def evaluate_students(df, answer_column="answer"):
    all_results = []
    for idx, row in df.iterrows():
        ans = str(row.get(answer_column, ""))

        result = evaluate_student_answer(ans)

        row_result = row.to_dict()
        row_result.update({
            #"student_answer": ans,
            "score": result["score"],
            "mistakes": json.dumps(result["mistakes"], ensure_ascii=False)
        })
        all_results.append(row_result)

    return pd.DataFrame(all_results)


# ---------- ตัวอย่างเรียกใช้ ----------
if __name__ == "__main__":
    input_csv = "/content/drive/MyDrive/S10(Sheet1).csv"      # ไฟล์ที่คุณอัปโหลด
    output_csv = "/content/sample_data/score3_S10.csv"     # ไฟล์ผลลัพธ์ที่ต้องการบันทึก

    df = pd.read_csv(input_csv)
    results_df = evaluate_students(df, answer_column="student_answer_2")  # ถ้าคอลัมน์ชื่อไม่ใช่ answer ให้แก้ตรงนี้

    results_df.to_csv(output_csv, index=False, encoding="utf-8-sig")

    print("✅ ประเมินเสร็จสิ้น บันทึกไฟล์แล้วที่:", output_csv)